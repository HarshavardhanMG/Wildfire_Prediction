{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b890305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP AND IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# --- PyTorch and Sklearn Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# --- TensorFlow for Data Loading ONLY ---\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Define data directory \n",
    "DATA_DIR = Path(\"../../data/raw/ndws_western_dataset\")\n",
    "print(f\"📁 Data directory: {DATA_DIR}\")\n",
    "print(f\"📂 Directory exists: {DATA_DIR.exists()}\")\n",
    "\n",
    "# Import necessary functions from other notebooks/modules\n",
    "sys.path.append('../../src')\n",
    "\n",
    "# --- CORRECTED TFRecord PARSING FUNCTION ---\n",
    "def parse_tfrecord_flexible(example):\n",
    "    \"\"\"\n",
    "    Parse TFRecord with the CORRECT feature description.\n",
    "    Instead of assuming string, we now correctly specify a 64x64 float tensor.\n",
    "    \"\"\"\n",
    "    feature_description = {}\n",
    "    \n",
    "    expected_features = [\n",
    "        'elevation', 'NDVI', 'erc', 'pr', 'pdsi', 'population',\n",
    "        'impervious', 'water', 'tmp_day', 'tmp_75', 'wind_avg', 'wind_75',\n",
    "        'wdir_wind', 'wdir_gust', 'gust_med', 'avg_sph', 'bi', 'chili',\n",
    "        'fuel1', 'fuel2', 'fuel3', 'viirs_PrevFireMask', 'viirs_FireMask'\n",
    "    ]\n",
    "    \n",
    "    # CRITICAL FIX: We now tell TensorFlow to expect a 64x64 array of floats.\n",
    "    for feat in expected_features:\n",
    "        feature_description[feat] = tf.io.FixedLenFeature([64, 64], tf.float32)\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(example, feature_description)\n",
    "    return parsed_features\n",
    "\n",
    "# NOTE: The decode_feature function is no longer needed and has been removed.\n",
    "\n",
    "print(\"\\n✅ Setup complete - data loading functions are now corrected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3375bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION FUNCTIONS (PYTORCH VERSION)\n",
    "def visualize_fire_predictions_pytorch(model, X_test, y_test, num_samples=4):\n",
    "    \"\"\"Visualize fire prediction results from a PyTorch model\"\"\"\n",
    "    if len(X_test) == 0:\n",
    "        print(\"❌ No test samples available for visualization\")\n",
    "        return\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    X_test_subset = X_test[:num_samples]\n",
    "    y_test_subset = y_test[:num_samples]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Transpose from (N, H, W, C) to (N, C, H, W) for PyTorch\n",
    "        X_test_tensor = torch.from_numpy(np.transpose(X_test_subset, (0, 3, 1, 2))).float().to(device)\n",
    "        predictions_tensor = model(X_test_tensor)\n",
    "        # Transpose back to (N, H, W, C) for visualization with Matplotlib\n",
    "        predictions = np.transpose(predictions_tensor.cpu().numpy(), (0, 2, 3, 1))\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        input_fire = X_test_subset[i, :, :, 0]\n",
    "        true_fire = y_test_subset[i, :, :, 0]\n",
    "        pred_fire = predictions[i, :, :, 0]\n",
    "\n",
    "        axes[i, 0].imshow(input_fire, cmap='Reds', vmin=0, vmax=1)\n",
    "        axes[i, 0].set_title(f'Sample {i+1}: Input Fire (t)')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(true_fire, cmap='Reds', vmin=0, vmax=1)\n",
    "        # --- CORRECTED LABEL ---\n",
    "        axes[i, 1].set_title(f'True Fire (t+1)')\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        axes[i, 2].imshow(pred_fire, cmap='Reds', vmin=0, vmax=1)\n",
    "        # --- CORRECTED LABEL ---\n",
    "        axes[i, 2].set_title(f'Predicted Fire (t+1)')\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"\\n📊 PREDICTION STATISTICS:\")\n",
    "    print(f\"🔥 True fire pixels in displayed samples: {np.sum(y_test_subset > 0.1)}\")\n",
    "    print(f\"🎯 Predicted fire pixels (threshold > 0.5): {np.sum(predictions > 0.5)}\")\n",
    "    print(f\"📈 Average prediction confidence: {np.mean(predictions):.4f}\")\n",
    "\n",
    "print(\"✅ PyTorch visualization function defined with corrected t+1 labels!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f51b8",
   "metadata": {},
   "source": [
    "# 🔥 SPATIAL FIRE SPREAD PREDICTION WITH U-NET ARCHITECTURE\n",
    "\n",
    "**CRITICAL FIX**: This section implements proper spatial fire spread prediction using:\n",
    "- ✅ **Raw spatial features** (64x64 grids) - NOT statistical summaries\n",
    "- ✅ **All 23 environmental features** as spatial inputs\n",
    "- ✅ **U-Net architecture** for pixel-level fire spread prediction\n",
    "- ✅ **Temporal prediction**: PrevFireMask(t) → FireMask(t+1)\n",
    "- ✅ **Research-based approach** following wildfire prediction literature\n",
    "\n",
    "**Key Point**: The engineered features above are for EDA/visualization only. All prediction uses RAW SPATIAL DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29663286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NEW DATA PROCESSOR FOR SINGLE-DAY (t -> t+1) PREDICTION (CORRECTED) ---\n",
    "\n",
    "class SingleDayFireDataProcessor:\n",
    "    \"\"\"\n",
    "    Processes raw TFRecord data for NEXT-DAY fire spread prediction\n",
    "    using ONLY the current day's data (no time-series context).\n",
    "    (Corrected to ensure fire mask is the first channel).\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir=DATA_DIR):\n",
    "        self.data_dir = data_dir\n",
    "        # Separate the fire feature from the environmental features\n",
    "        self.fire_feature = 'viirs_PrevFireMask'\n",
    "        self.environmental_features = [\n",
    "            'elevation', 'NDVI', 'erc', 'pr', 'pdsi', 'population',\n",
    "            'impervious', 'water', 'tmp_day', 'tmp_75', 'wind_avg', 'wind_75',\n",
    "            'wdir_wind', 'wdir_gust', 'gust_med', 'avg_sph', 'bi', 'chili',\n",
    "            'fuel1', 'fuel2', 'fuel3'\n",
    "        ]\n",
    "        self.target_feature = 'viirs_FireMask'\n",
    "\n",
    "    def load_raw_spatial_data(self, max_sequences=None):\n",
    "        \"\"\"\n",
    "        Load and create single-day sequences.\n",
    "        Input X: All features from day 't', with fire mask as channel 0.\n",
    "        Target Y: The FireMask from day 't+1'.\n",
    "        \"\"\"\n",
    "        print(\"🔥 Loading RAW SPATIAL DATA for SINGLE-DAY (t -> t+1) prediction...\")\n",
    "        \n",
    "        tfrecord_files = list(self.data_dir.glob(\"*.tfrecord\"))\n",
    "        if not tfrecord_files:\n",
    "            print(\"❌ No TFRecord files found!\")\n",
    "            return None, None\n",
    "        print(f\"📁 Found {len(tfrecord_files)} TFRecord files\")\n",
    "\n",
    "        all_samples_flat = []\n",
    "        for file_path in tfrecord_files:\n",
    "            dataset = tf.data.TFRecordDataset(str(file_path))\n",
    "            for raw_record in dataset:\n",
    "                try:\n",
    "                    parsed_sample = parse_tfrecord_flexible(raw_record)\n",
    "                    sample_data = {name: tensor.numpy() for name, tensor in parsed_sample.items()}\n",
    "                    if self.fire_feature in sample_data and self.target_feature in sample_data:\n",
    "                        all_samples_flat.append(sample_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"❗️ FAILED TO PROCESS A RECORD in {file_path.name}. Error: {e}\")\n",
    "                    break\n",
    "            else: continue\n",
    "            break\n",
    "        \n",
    "        print(f\"  ...Loaded {len(all_samples_flat)} total individual samples.\")\n",
    "\n",
    "        if not all_samples_flat:\n",
    "             print(\"❌ No valid samples were loaded.\")\n",
    "             return None, None\n",
    "\n",
    "        # --- CORRECTED SINGLE-DAY LOGIC ---\n",
    "        spatial_inputs, spatial_targets = [], []\n",
    "        \n",
    "        for i in range(len(all_samples_flat) - 1):\n",
    "            if max_sequences and len(spatial_inputs) >= max_sequences:\n",
    "                break\n",
    "\n",
    "            current_day_sample = all_samples_flat[i]\n",
    "            next_day_sample = all_samples_flat[i + 1]\n",
    "\n",
    "            # --- Assemble the Input Tensor (X) with corrected order ---\n",
    "            input_features = []\n",
    "            \n",
    "            # 1. Add the fire mask FIRST to ensure it is channel 0\n",
    "            if self.fire_feature in current_day_sample:\n",
    "                input_features.append(current_day_sample[self.fire_feature].reshape(64, 64, 1))\n",
    "\n",
    "            # 2. Add all other environmental features\n",
    "            for feature_name in self.environmental_features:\n",
    "                if feature_name in current_day_sample:\n",
    "                    input_features.append(current_day_sample[feature_name].reshape(64, 64, 1))\n",
    "            \n",
    "            # --- Assemble the Target Tensor (y) ---\n",
    "            target_mask = next_day_sample[self.target_feature].reshape(64, 64, 1)\n",
    "\n",
    "            # Check if all features were found (1 fire + 21 env)\n",
    "            if len(input_features) == len(self.environmental_features) + 1:\n",
    "                spatial_inputs.append(np.concatenate(input_features, axis=2))\n",
    "                spatial_targets.append(target_mask)\n",
    "\n",
    "        if not spatial_inputs:\n",
    "            print(\"❌ Could not create any sequences with the single-day logic!\")\n",
    "            return None, None\n",
    "            \n",
    "        X_spatial = np.array(spatial_inputs, dtype=np.float32)\n",
    "        y_spatial = np.array(spatial_targets, dtype=np.float32)\n",
    "\n",
    "        print(f\"\\n✅ SINGLE-DAY DATA LOADING COMPLETE\")\n",
    "        print(f\"📊 Spatial Input Shape: {X_spatial.shape}\")\n",
    "        print(f\"📊 Spatial Target Shape: {y_spatial.shape}\")\n",
    "        return X_spatial, y_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PYTORCH UNET++ ARCHITECTURE, LOSS FUNCTION, AND TRAINING FUNCTION ---\n",
    "\n",
    "# --- 1. LOSS FUNCTION: BCE + Dice (Unchanged) ---\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1e-6):\n",
    "        inputs_flat = inputs.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        bce_loss = nn.BCELoss()(inputs_flat, targets_flat)\n",
    "        intersection = (inputs_flat * targets_flat).sum()\n",
    "        dice_score = (2. * intersection + smooth) / (inputs_flat.sum() + targets_flat.sum() + smooth)\n",
    "        dice_loss = 1 - dice_score\n",
    "        return self.weight * bce_loss + (1 - self.weight) * dice_loss\n",
    "\n",
    "# --- 2. U-NET++ MODEL DEFINITION IN PYTORCH ---\n",
    "# --- PYTORCH UNET++ ARCHITECTURE (WITH BATCH NORMALIZATION) ---\n",
    "class FireUNetPlusPlus(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet++ with the CRITICAL addition of Batch Normalization to stabilize training.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, filters_base=32):\n",
    "        super(FireUNetPlusPlus, self).__init__()\n",
    "\n",
    "        # --- MODIFIED CONV BLOCK WITH BATCH NORMALIZATION ---\n",
    "        def _conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_c), # Add BatchNorm\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_c), # Add BatchNorm\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # The rest of the U-Net++ architecture is IDENTICAL\n",
    "        nb_filter = [filters_base, filters_base*2, filters_base*4, filters_base*8, filters_base*16]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv0_0 = _conv_block(in_channels, nb_filter[0])\n",
    "        self.conv1_0 = _conv_block(nb_filter[0], nb_filter[1])\n",
    "        self.conv2_0 = _conv_block(nb_filter[1], nb_filter[2])\n",
    "        self.conv3_0 = _conv_block(nb_filter[2], nb_filter[3])\n",
    "        self.conv4_0 = _conv_block(nb_filter[3], nb_filter[4])\n",
    "        self.conv0_1 = _conv_block(nb_filter[0]+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_1 = _conv_block(nb_filter[1]+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_1 = _conv_block(nb_filter[2]+nb_filter[3], nb_filter[2])\n",
    "        self.conv3_1 = _conv_block(nb_filter[3]+nb_filter[4], nb_filter[3])\n",
    "        self.conv0_2 = _conv_block(nb_filter[0]*2+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_2 = _conv_block(nb_filter[1]*2+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_2 = _conv_block(nb_filter[2]*2+nb_filter[3], nb_filter[2])\n",
    "        self.conv0_3 = _conv_block(nb_filter[0]*3+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_3 = _conv_block(nb_filter[1]*3+nb_filter[2], nb_filter[1])\n",
    "        self.conv0_4 = _conv_block(nb_filter[0]*4+nb_filter[1], nb_filter[0])\n",
    "        self.final = nn.Conv2d(nb_filter[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # The forward pass is IDENTICAL\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "        output = self.final(x0_4)\n",
    "        return torch.sigmoid(output)\n",
    "\n",
    "\n",
    "# --- 3. TRAINING FUNCTION (Modified to use FireUNetPlusPlus) ---\n",
    "def train_fire_unet_cv_pytorch(X_spatial, y_spatial, n_splits=5, epochs=20, batch_size=4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"🚀 INITIATING U-NET++ TRAINING ON {device} WITH {n_splits}-FOLD CV\")\n",
    "    print(f\"🎯 Main Metric: Average Precision (AP)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_ap_scores = []\n",
    "    last_model = None\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_spatial)):\n",
    "        print(f\"\\n========== FOLD {fold + 1}/{n_splits} ==========\")\n",
    "        X_train, X_val = X_spatial[train_idx], X_spatial[val_idx]\n",
    "        y_train, y_val = y_spatial[train_idx], y_spatial[val_idx]\n",
    "\n",
    "        X_train_t = np.transpose(X_train, (0, 3, 1, 2))\n",
    "        X_val_t = np.transpose(X_val, (0, 3, 1, 2))\n",
    "        y_train_t = (np.transpose(y_train, (0, 3, 1, 2)) > 0.1).astype(np.float32)\n",
    "        y_val_t = (np.transpose(y_val, (0, 3, 1, 2)) > 0.1).astype(np.float32)\n",
    "        \n",
    "        channel_means = np.mean(X_train_t, axis=(0, 2, 3), keepdims=True)\n",
    "        channel_stds = np.std(X_train_t, axis=(0, 2, 3), keepdims=True)\n",
    "        channel_stds[channel_stds == 0] = 1\n",
    "\n",
    "        X_train_norm = (X_train_t - channel_means) / channel_stds\n",
    "        X_val_norm = (X_val_t - channel_means) / channel_stds\n",
    "        \n",
    "        train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train_norm), torch.from_numpy(y_train_t)), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(torch.from_numpy(X_val_norm), torch.from_numpy(y_val_t)), batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # <<< CHANGE: Use FireUNetPlusPlus instead of the old model >>>\n",
    "        model = FireUNetPlusPlus(in_channels=X_train_norm.shape[1], out_channels=1).to(device)\n",
    "        \n",
    "        criterion = BCEDiceLoss(weight=0.5) # Stable weight for initial run\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        print(f\"🔥 STARTING TRAINING for {epochs} epochs...\")\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            print(f\"  Epoch {epoch + 1}/{epochs} - Training Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs.to(device))\n",
    "                all_preds.append(outputs.cpu().numpy().flatten())\n",
    "                all_labels.append(labels.numpy().flatten())\n",
    "        \n",
    "        ap_score = average_precision_score(np.concatenate(all_labels), np.concatenate(all_preds))\n",
    "        fold_ap_scores.append(ap_score)\n",
    "        print(f\"✅ Fold {fold + 1} Validation - AP: {ap_score:.4f}\")\n",
    "        last_model = model\n",
    "\n",
    "    print(\"\\n\\n📊 CROSS-VALIDATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  - Mean AP ± Std Dev: {np.mean(fold_ap_scores):.4f} ± {np.std(fold_ap_scores):.4f}\")\n",
    "    \n",
    "    if last_model:\n",
    "        model_save_path = \"final_fire_unet_plus_plus.pth\" # New save name\n",
    "        torch.save(last_model.state_dict(), model_save_path)\n",
    "        print(f\"\\n💾 Final model from the last fold saved to '{model_save_path}'\")\n",
    "    \n",
    "    return last_model, fold_ap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXECUTION FOR THE SINGLE-DAY MODEL WITH UNET++ ---\n",
    "\n",
    "# 1. Load data using the SingleDayFireDataProcessor (no change here)\n",
    "single_day_processor = SingleDayFireDataProcessor()\n",
    "X_spatial_single, y_spatial_single = single_day_processor.load_raw_spatial_data(max_sequences=500)\n",
    "\n",
    "# 2. Train the UNet++ model with the single-day data\n",
    "final_model_single_pp = None \n",
    "cv_results_single_pp = []\n",
    "\n",
    "if X_spatial_single is not None:\n",
    "    print(\"\\n--- Training SINGLE-DAY UNet++ Model ---\")\n",
    "    \n",
    "    final_model_single_pp, cv_results_single_pp = train_fire_unet_cv_pytorch(\n",
    "        X_spatial_single, y_spatial_single,\n",
    "        n_splits=3,\n",
    "        epochs=15, \n",
    "        batch_size=4\n",
    "    )\n",
    "    \n",
    "    if cv_results_single_pp:\n",
    "        # Save the model with a distinct name\n",
    "        torch.save(final_model_single_pp.state_dict(), \"single_day_fire_unet_plus_plus.pth\")\n",
    "        print(\"\\n💾 Single-day UNet++ model saved!\")\n",
    "        print(\"\\n🎉 SINGLE-DAY UNet++ TRAINING COMPLETED!\")\n",
    "    else:\n",
    "        print(f\"❌ Single-day UNet++ training failed!\")\n",
    "else:\n",
    "    print(f\"❌ Cannot train Single-day UNet++ - no data loaded!\")\n",
    "    \n",
    "# 3. Visualize the results from the single-day UNet++ model\n",
    "if final_model_single_pp is not None:\n",
    "    print(f\"\\n🎨 GENERATING VISUALIZATIONS for SINGLE-DAY UNet++ model...\")\n",
    "    \n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    train_indices, val_indices = list(kfold.split(X_spatial_single))[-1]\n",
    "    \n",
    "    X_train_last_fold = X_spatial_single[train_indices]\n",
    "    X_test_viz = X_spatial_single[val_indices]\n",
    "    y_test_viz = y_spatial_single[val_indices]\n",
    "    \n",
    "    num_viz_samples = min(4, len(X_test_viz))\n",
    "    if num_viz_samples > 0:\n",
    "        X_train_t = np.transpose(X_train_last_fold, (0, 3, 1, 2))\n",
    "        channel_means = np.mean(X_train_t, axis=(0, 2, 3), keepdims=True)\n",
    "        channel_stds = np.std(X_train_t, axis=(0, 2, 3), keepdims=True)\n",
    "        channel_stds[channel_stds == 0] = 1\n",
    "\n",
    "        X_test_viz_t = np.transpose(X_test_viz[:num_viz_samples], (0, 3, 1, 2))\n",
    "        X_test_norm_t = (X_test_viz_t - channel_means) / channel_stds\n",
    "        X_test_norm = np.transpose(X_test_norm_t, (0, 2, 3, 1))\n",
    "        y_test_binary = (y_test_viz[:num_viz_samples] > 0.1).astype(np.float32)\n",
    "        \n",
    "        visualize_fire_predictions_pytorch(\n",
    "            final_model_single_pp, X_test_norm, y_test_binary, num_samples=num_viz_samples\n",
    "        )\n",
    "else:\n",
    "    print(f\"\\n⚠️ Single-day UNet++ model not available for evaluation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
